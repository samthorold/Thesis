{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size-Value-Momentum/Investment Sorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_bkts(df, var, brkpts, prefix=None, suffix=\"Bkt\"):\n",
    "    \"\"\"\n",
    "    Assigns buckets to column `var` based on percentiles in `brkpts`.\n",
    "    \n",
    "    Assumes breakpoints are already in dataframe `df` and are named the same as given in `brkpts`.\n",
    "    Buckets are integers beginning with 1 ending with len(brkpts).\n",
    "    \"\"\"\n",
    "\n",
    "    if not prefix:\n",
    "        prefix = var\n",
    "    varbkt = prefix + suffix\n",
    "\n",
    "    df[varbkt] = pd.np.NaN\n",
    "\n",
    "    for i, brkpt in enumerate(brkpts):  # index begins at 0\n",
    "        if i==0:\n",
    "            df.loc[df[var]<=df[brkpt], varbkt] = 1\n",
    "        else:\n",
    "            df.loc[(df[var]>df[brkpts[i-1]]) & (df[var]<=df[brkpt]), varbkt] = i + 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_csv(\"C:/Data/Thesis/Combined_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date = pd.to_datetime(df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_bkts = pd.read_csv(\"C:/Data/Thesis/Bkts_Jun_ME_2.csv\")\n",
    "\n",
    "df = df.merge(size_bkts, on=[\"PERMNO\", \"HP\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2370047, 41)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = df[df.ME_JunBkt==1]\n",
    "\n",
    "sdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $BM^m$ Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk = sdf[[\"date\", \"BMm\"]][(sdf.EXCHCD==1) & (sdf.BMmOK)].groupby(\"date\")\n",
    "brk = brk.quantile(pd.np.array(range(1, 21))/20).unstack()\n",
    "brk.columns = brk.columns.droplevel(0)\n",
    "\n",
    "brk.to_csv(\"C:/Data/Thesis/Brks_Small_BMm.csv\")  # column headers are decimals, potential floating point precision garbage\n",
    "\n",
    "sdf = sdf.merge(brk.reset_index(\"date\"), on=\"date\", how=\"left\")\n",
    "\n",
    "sdf = assign_bkts(sdf, \"BMm\", [.25, .5, .75, 1.])\n",
    "\n",
    "sdf = sdf.drop(pd.np.array(range(1, 21))/20, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk = sdf[[\"date\", \"Prior\"]][(sdf.EXCHCD==1) & (sdf.PriorOK)].groupby(\"date\")\n",
    "brk = brk.quantile(pd.np.array(range(1, 21))/20).unstack()\n",
    "brk.columns = brk.columns.droplevel(0)\n",
    "\n",
    "brk.to_csv(\"C:/Data/Thesis/Brks_Small_Prior.csv\")  # column headers are decimals, potential floating point precision garbage\n",
    "\n",
    "sdf = sdf.merge(brk.reset_index(\"date\"), on=\"date\", how=\"left\")\n",
    "\n",
    "sdf = assign_bkts(sdf, \"Prior\", [.25, .5, .75, 1.])\n",
    "\n",
    "sdf = sdf.drop(pd.np.array(range(1, 21))/20, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $BM$ Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk = sdf[(sdf.EXCHCD==1) & (sdf.date.dt.month==7) & (sdf.BMOK)][[\"HP\", \"BMm\"]].groupby(\"HP\")\n",
    "brk = brk.quantile(pd.np.array(range(1, 21))/20).unstack()\n",
    "brk.columns = brk.columns.droplevel(0)\n",
    "\n",
    "brk.to_csv(\"C:/Data/Thesis/Brks_Small_BM.csv\")  # column headers are decimals, potential floating point precision garbage\n",
    "\n",
    "sdf = sdf.merge(brk.reset_index(\"HP\"), on=\"HP\", how=\"left\")\n",
    "\n",
    "sdf = assign_bkts(sdf, \"BM\", [.25, .5, .75, 1.])\n",
    "\n",
    "sdf = sdf.drop(pd.np.array(range(1, 21))/20, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inv Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk = sdf[(sdf.EXCHCD==1) & (sdf.date.dt.month==7) & (~sdf.Inv.isna())][[\"HP\", \"Inv\"]].groupby(\"HP\")\n",
    "brk = brk.quantile(pd.np.array(range(1, 21))/20).unstack()\n",
    "brk.columns = brk.columns.droplevel(0)\n",
    "\n",
    "brk.to_csv(\"C:/Data/Thesis/Brks_Small_Inv.csv\")  # column headers are decimals, potential floating point precision garbage\n",
    "\n",
    "sdf = sdf.merge(brk.reset_index(\"HP\"), on=\"HP\", how=\"left\")\n",
    "\n",
    "sdf = assign_bkts(sdf, \"Inv\", [.25, .5, .75, 1.])\n",
    "\n",
    "sdf = sdf.drop(pd.np.array(range(1, 21))/20, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size-Value-Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RET BMm BM Prior Inv BE_Growth_Future \n"
     ]
    }
   ],
   "source": [
    "grp, ix = [\"date\", \"BMmBkt\", \"PriorBkt\"], ((sdf.BMmOK) & (sdf.PriorOK))\n",
    "\n",
    "sdf[\"BktSize\"] = sdf[ix].groupby(grp)[\"L1_ME\"].transform(\"sum\")\n",
    "\n",
    "for col in [\"RET\", \"BMm\", \"BM\", \"Prior\", \"Inv\", \"BE_Growth_Future\"]:\n",
    "    print(col, end=\" \")\n",
    "    sdf[\"Wt\"+col] = sdf[col] * sdf.L1_ME / sdf.BktSize\n",
    "    bkt = sdf[ix].groupby(grp)[\"Wt\"+col].sum()\n",
    "    bkt = bkt.reset_index(grp[1:])\n",
    "    bkt[grp[1]+grp[2]] = \"S\" + bkt[grp[1]].astype(\"int\").astype(\"str\") + bkt[grp[2]].astype(\"int\").astype(\"str\")\n",
    "    bkt = bkt.pivot(columns=grp[1]+grp[2], values=\"Wt\"+col).reset_index(\"date\")\n",
    "    bkt.to_csv(\"C:/Data/Thesis/Size_BMm_Prior_S_{}.csv\".format(col))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size-Value-Investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RET BMm BM Prior Inv BE_Growth_Future \n"
     ]
    }
   ],
   "source": [
    "grp, ix = [\"date\", \"BMBkt\", \"InvBkt\"], ((sdf.BMOK) & (~sdf.Inv.isna()))\n",
    "\n",
    "sdf[\"BktSize\"] = sdf[ix].groupby(grp)[\"Size\"].transform(\"sum\")\n",
    "\n",
    "for col in [\"RET\", \"BMm\", \"BM\", \"Prior\", \"Inv\", \"BE_Growth_Future\"]:\n",
    "    print(col, end=\" \")\n",
    "    sdf[\"Wt\"+col] = sdf[col] * sdf.Size / sdf.BktSize\n",
    "    bkt = sdf[ix].groupby(grp)[\"Wt\"+col].sum()\n",
    "    bkt = bkt.reset_index(grp[1:])\n",
    "    bkt[grp[1]+grp[2]] = \"S\" + bkt[grp[1]].astype(\"int\").astype(\"str\") + bkt[grp[2]].astype(\"int\").astype(\"str\")\n",
    "    bkt = bkt.pivot(columns=grp[1]+grp[2], values=\"Wt\"+col).reset_index(\"date\")\n",
    "    bkt.to_csv(\"C:/Data/Thesis/Size_BM_Inv_S_{}.csv\".format(col))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581661, 41)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = df[df.ME_JunBkt==2]\n",
    "\n",
    "sdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $BM^m$ Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk = sdf[[\"date\", \"BMm\"]][(sdf.EXCHCD==1) & (sdf.BMmOK)].groupby(\"date\")\n",
    "brk = brk.quantile(pd.np.array(range(1, 21))/20).unstack()\n",
    "brk.columns = brk.columns.droplevel(0)\n",
    "\n",
    "brk.to_csv(\"C:/Data/Thesis/Brks_Big_BMm.csv\")  # column headers are decimals, potential floating point precision garbage\n",
    "\n",
    "sdf = sdf.merge(brk.reset_index(\"date\"), on=\"date\", how=\"left\")\n",
    "\n",
    "sdf = assign_bkts(sdf, \"BMm\", [.25, .5, .75, 1.])\n",
    "\n",
    "sdf = sdf.drop(pd.np.array(range(1, 21))/20, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk = sdf[[\"date\", \"Prior\"]][(sdf.EXCHCD==1) & (sdf.PriorOK)].groupby(\"date\")\n",
    "brk = brk.quantile(pd.np.array(range(1, 21))/20).unstack()\n",
    "brk.columns = brk.columns.droplevel(0)\n",
    "\n",
    "brk.to_csv(\"C:/Data/Thesis/Brks_Big_Prior.csv\")  # column headers are decimals, potential floating point precision garbage\n",
    "\n",
    "sdf = sdf.merge(brk.reset_index(\"date\"), on=\"date\", how=\"left\")\n",
    "\n",
    "sdf = assign_bkts(sdf, \"Prior\", [.25, .5, .75, 1.])\n",
    "\n",
    "sdf = sdf.drop(pd.np.array(range(1, 21))/20, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $BM$ Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk = sdf[(sdf.EXCHCD==1) & (sdf.date.dt.month==7) & (sdf.BMOK)][[\"HP\", \"BMm\"]].groupby(\"HP\")\n",
    "brk = brk.quantile(pd.np.array(range(1, 21))/20).unstack()\n",
    "brk.columns = brk.columns.droplevel(0)\n",
    "\n",
    "brk.to_csv(\"C:/Data/Thesis/Brks_Big_BM.csv\")  # column headers are decimals, potential floating point precision garbage\n",
    "\n",
    "sdf = sdf.merge(brk.reset_index(\"HP\"), on=\"HP\", how=\"left\")\n",
    "\n",
    "sdf = assign_bkts(sdf, \"BM\", [.25, .5, .75, 1.])\n",
    "\n",
    "sdf = sdf.drop(pd.np.array(range(1, 21))/20, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inv Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk = sdf[(sdf.EXCHCD==1) & (sdf.date.dt.month==7) & (~sdf.Inv.isna())][[\"HP\", \"Inv\"]].groupby(\"HP\")\n",
    "brk = brk.quantile(pd.np.array(range(1, 21))/20).unstack()\n",
    "brk.columns = brk.columns.droplevel(0)\n",
    "\n",
    "brk.to_csv(\"C:/Data/Thesis/Brks_Big_Inv.csv\")  # column headers are decimals, potential floating point precision garbage\n",
    "\n",
    "sdf = sdf.merge(brk.reset_index(\"HP\"), on=\"HP\", how=\"left\")\n",
    "\n",
    "sdf = assign_bkts(sdf, \"Inv\", [.25, .5, .75, 1.])\n",
    "\n",
    "sdf = sdf.drop(pd.np.array(range(1, 21))/20, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size-Value-Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RET BMm BM Prior Inv BE_Growth_Future \n"
     ]
    }
   ],
   "source": [
    "grp, ix = [\"date\", \"BMmBkt\", \"PriorBkt\"], ((sdf.BMmOK) & (sdf.PriorOK))\n",
    "\n",
    "sdf[\"BktSize\"] = sdf[ix].groupby(grp)[\"L1_ME\"].transform(\"sum\")\n",
    "\n",
    "for col in [\"RET\", \"BMm\", \"BM\", \"Prior\", \"Inv\", \"BE_Growth_Future\"]:\n",
    "    print(col, end=\" \")\n",
    "    sdf[\"Wt\"+col] = sdf[col] * sdf.L1_ME / sdf.BktSize\n",
    "    bkt = sdf[ix].groupby(grp)[\"Wt\"+col].sum()\n",
    "    bkt = bkt.reset_index(grp[1:])\n",
    "    bkt[grp[1]+grp[2]] = \"B\" + bkt[grp[1]].astype(\"int\").astype(\"str\") + bkt[grp[2]].astype(\"int\").astype(\"str\")\n",
    "    bkt = bkt.pivot(columns=grp[1]+grp[2], values=\"Wt\"+col).reset_index(\"date\")\n",
    "    bkt.to_csv(\"C:/Data/Thesis/Size_BMm_Prior_B_{}.csv\".format(col))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size-Value-Investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RET BMm BM Prior Inv BE_Growth_Future \n"
     ]
    }
   ],
   "source": [
    "grp, ix = [\"date\", \"BMBkt\", \"InvBkt\"], ((sdf.BMOK) & (~sdf.Inv.isna()))\n",
    "\n",
    "sdf[\"BktSize\"] = sdf[ix].groupby(grp)[\"Size\"].transform(\"sum\")\n",
    "\n",
    "for col in [\"RET\", \"BMm\", \"BM\", \"Prior\", \"Inv\", \"BE_Growth_Future\"]:\n",
    "    print(col, end=\" \")\n",
    "    sdf[\"Wt\"+col] = sdf[col] * sdf.Size / sdf.BktSize\n",
    "    bkt = sdf[ix].groupby(grp)[\"Wt\"+col].sum()\n",
    "    bkt = bkt.reset_index(grp[1:])\n",
    "    bkt[grp[1]+grp[2]] = \"B\" + bkt[grp[1]].astype(\"int\").astype(\"str\") + bkt[grp[2]].astype(\"int\").astype(\"str\")\n",
    "    bkt = bkt.pivot(columns=grp[1]+grp[2], values=\"Wt\"+col).reset_index(\"date\")\n",
    "    bkt.to_csv(\"C:/Data/Thesis/Size_BM_Inv_B_{}.csv\".format(col))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Small and Big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.42,  0.33,  0.36,  0.62],\n",
       "        [ 0.08,  0.1 ,  0.11,  0.1 ],\n",
       "        [ 0.01,  0.05,  0.05,  0.04],\n",
       "        [-0.09, -0.02,  0.  , -0.02]],\n",
       "\n",
       "       [[ 0.42,  0.25,  0.25,  0.5 ],\n",
       "        [ 0.11,  0.1 ,  0.11,  0.13],\n",
       "        [ 0.07,  0.08,  0.08,  0.09],\n",
       "        [ 0.01,  0.04,  0.04,  0.03]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = \"Size_BMm_Prior\"\n",
    "\n",
    "#for col in [\"RET\", \"BMm\", \"BM\", \"Prior\", \"Inv\", \"BE_Growth_Future\"]:\n",
    "col = \"BE_Growth_Future\"\n",
    "small = pd.read_csv(\"C:/Data/Thesis/{}_S_{}.csv\".format(prefix, col)).iloc[:, 1:]\n",
    "small.date = pd.to_datetime(small.date)\n",
    "big = pd.read_csv(\"C:/Data/Thesis/{}_B_{}.csv\".format(prefix, col)).iloc[:, 1:]\n",
    "big.date = pd.to_datetime(big.date)\n",
    "x = small.merge(big, how=\"left\").set_index(\"date\")[\"1963-07\":\"2017-12\"].replace([pd.np.inf, -pd.np.inf], pd.np.nan).mean()\n",
    "\n",
    "x.round(2).values.reshape([2, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.6 ,  0.49,  0.28,  0.42],\n",
       "        [ 0.06,  0.09,  0.12,  0.16],\n",
       "        [ 0.03,  0.06,  0.09,  0.11],\n",
       "        [-0.02,  0.01,  0.03,  0.05]],\n",
       "\n",
       "       [[ 0.28,  0.21,  0.17,  0.4 ],\n",
       "        [ 0.09,  0.11,  0.12,  0.17],\n",
       "        [ 0.06,  0.08,  0.11,  0.14],\n",
       "        [ 0.03,  0.05,  0.08,  0.1 ]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix = \"Size_BM_Inv\"\n",
    "\n",
    "#for col in [\"RET\", \"BMm\", \"BM\", \"Prior\", \"Inv\", \"BE_Growth_Future\"]:\n",
    "col = \"BE_Growth_Future\"\n",
    "small = pd.read_csv(\"C:/Data/Thesis/{}_S_{}.csv\".format(prefix, col)).iloc[:, 1:]\n",
    "small.date = pd.to_datetime(small.date)\n",
    "big = pd.read_csv(\"C:/Data/Thesis/{}_B_{}.csv\".format(prefix, col)).iloc[:, 1:]\n",
    "big.date = pd.to_datetime(big.date)\n",
    "x = small.merge(big, how=\"left\").set_index(\"date\")[\"1963-07\":\"2017-12\"].replace([pd.np.inf, -pd.np.inf], pd.np.nan).mean()\n",
    "\n",
    "x.round(2).values.reshape([2, 4, 4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
