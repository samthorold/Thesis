{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size-Value-Momentum/Investment Sorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import jinja2\n",
    "import pandas as pd\n",
    "\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/samth/Dropbox/Thesis/Tex/Tables/\"\n",
    "\n",
    "env = jinja2.Environment(\n",
    "    block_start_string='-%', block_end_string='%-',\n",
    "    variable_start_string='=%', variable_end_string='%=',\n",
    "    loader=jinja2.FileSystemLoader(path)\n",
    ")\n",
    "\n",
    "template = env.get_template(\"_K_I_J_chars_template.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"RET\", \"BMm\", \"BM\", \"Prior\", \"CP\", \"Var_ret\", \"L1_Var_ret\", \"Inv\", \"F1_Inv\", \"BE_Growth_Future\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_bkts(df, var, brkpts, prefix=None, suffix=\"Bkt\"):\n",
    "    \"\"\"\n",
    "    Assigns buckets to column `var` based on percentiles in `brkpts`.\n",
    "    \n",
    "    Assumes breakpoints are already in dataframe `df` and are named the same as given in `brkpts`.\n",
    "    Buckets are integers beginning with 1 ending with len(brkpts).\n",
    "    \"\"\"\n",
    "\n",
    "    if not prefix:\n",
    "        prefix = var\n",
    "    varbkt = prefix + suffix\n",
    "\n",
    "    df[varbkt] = pd.np.NaN\n",
    "\n",
    "    for i, brkpt in enumerate(brkpts):  # index begins at 0\n",
    "        if i==0:\n",
    "            df.loc[df[var]<=df[brkpt], varbkt] = 1\n",
    "        else:\n",
    "            df.loc[(df[var]>df[brkpts[i-1]]) & (df[var]<=df[brkpt]), varbkt] = i + 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_csv(\"C:/Data/Thesis/Combined_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date = pd.to_datetime(df.date)\n",
    "#df.date = df.date.astype(pd.Timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_bkts = pd.read_csv(\"C:/Data/Thesis/Bkts_Jun_ME_2.csv\")\n",
    "\n",
    "df = df.merge(size_bkts, on=[\"PERMNO\", \"HP\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ME_brk = pd.read_csv(\"C:/Data/Thesis/Brks_Months_ME.csv\")\n",
    "\n",
    "pcts = [.5, 1.]\n",
    "\n",
    "ME_brk = ME_brk.rename(columns=dict(zip([str(pct) for pct in pcts], pcts)))\n",
    "ME_brk.date = pd.to_datetime(ME_brk.date, format=\"%m/%d/%Y\")  #.astype(pd.Timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('<M8[ns]'), dtype('<M8[ns]'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.dtype, ME_brk.date.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(ME_brk[[\"date\",] + pcts], on=\"date\", how=\"left\")\n",
    "\n",
    "df = assign_bkts(df, \"ME\", pcts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"L1_MEBkt\"] = df.groupby(\"PERMNO\")[\"MEBkt\"].shift(1)\n",
    "df = df.drop(pcts, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.MEBkt.isna().sum() != df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcts = [.25, .5, .75, 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = pd.read_stata(\"C:/Data/Thesis/Var_monthly.dta\")\n",
    "\n",
    "var = var.rename(columns={\"permno\": \"PERMNO\"})\n",
    "\n",
    "df[\"yr\"] = df.date.dt.year\n",
    "df[\"mnth\"] = df.date.dt.month\n",
    "\n",
    "df = df.merge(var[[\"PERMNO\", \"yr\", \"mnth\", \"Var_ret\", \"N_good\"]], on=[\"PERMNO\", \"yr\", \"mnth\"], how=\"left\")\n",
    "\n",
    "df[\"L1_Var_ret\"] = df.groupby(\"PERMNO\")[\"Var_ret\"].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"F1_Inv\"] = df.groupby(\"PERMNO\")[\"Inv\"].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PERMNO', 'date', 'EXCHCD', 'SICCD', 'TICKER', 'DCLRDT',\n",
       "       'DLSTCD', 'DISTCD', 'FACPR', 'FACSHR', 'DLRET', 'PRC', 'RET', 'SHROUT',\n",
       "       'CFACPR', 'CFACSHR', 'HP', 'ME', 'ME_Jun', 'ME_Dec', 'Ri', 'L1_Ri',\n",
       "       'RiFctr', 'Size', 'Prior', 'L1_ME', 'PriorOK', 'BE', 'BE_Growth_Future',\n",
       "       'OP06', 'OP06OK', 'OP16', 'ACC', 'CP', 'Inv', 'BM', 'BMOK', 'BMm',\n",
       "       'BMmOK', 'ME_JunBkt', 'MEBkt', 'L1_MEBkt', 'yr', 'mnth', 'Var_ret',\n",
       "       'N_good', 'L1_Var_ret', 'F1_Inv'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2495873, 49), dtype('<M8[ns]'), dtype('<M8[ns]'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = df[df.L1_MEBkt==1]\n",
    "\n",
    "sdf.shape, sdf.date.dtype, df.date.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $BM^m$ Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk = sdf[[\"date\", \"BMm\"]][(sdf.EXCHCD==1) & (sdf.BMmOK)].groupby(\"date\")\n",
    "brk = brk.quantile(pcts).unstack()\n",
    "brk.columns = brk.columns.droplevel(0)\n",
    "\n",
    "brk = brk.reset_index(\"date\")\n",
    "brk.date = pd.to_datetime(brk.date)\n",
    "\n",
    "sdf = sdf.merge(brk, on=\"date\", how=\"left\")\n",
    "sdf = assign_bkts(sdf, \"BMm\", pcts)\n",
    "\n",
    "sdf = sdf.drop(pcts, axis=1)\n",
    "\n",
    "assert sdf.BMmBkt.isna().sum() != sdf.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk = sdf[[\"date\", \"Prior\"]][(sdf.EXCHCD==1) & (sdf.PriorOK)].groupby(\"date\")\n",
    "brk = brk.quantile(pcts).unstack()\n",
    "brk.columns = brk.columns.droplevel(0)\n",
    "\n",
    "brk = brk.reset_index(\"date\")\n",
    "brk.date = pd.to_datetime(brk.date)\n",
    "\n",
    "sdf = sdf.merge(brk, on=\"date\", how=\"left\")\n",
    "sdf = assign_bkts(sdf, \"Prior\", pcts)\n",
    "\n",
    "sdf = sdf.drop(pcts, axis=1)\n",
    "\n",
    "assert sdf.PriorBkt.isna().sum() != sdf.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size-Value-Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp, ix = [\"date\", \"BMmBkt\", \"PriorBkt\"], ((~sdf.L1_ME.isna()) & (sdf.BMmOK) & (sdf.PriorOK))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RET BMm BM Prior CP Var_ret L1_Var_ret Inv F1_Inv BE_Growth_Future \n"
     ]
    }
   ],
   "source": [
    "sdf[\"BktSize\"] = sdf[ix].groupby(grp)[\"L1_ME\"].transform(\"sum\")\n",
    "\n",
    "for col in cols:\n",
    "    print(col, end=\" \")\n",
    "    sdf[\"Wt\"+col] = sdf[col] * sdf.L1_ME / sdf.BktSize\n",
    "    bkt = sdf[ix].groupby(grp)[\"Wt\"+col].sum()\n",
    "    bkt = bkt.reset_index(grp[1:])\n",
    "    bkt[grp[1]+grp[2]] = \"S\" + bkt[grp[1]].astype(\"int\").astype(\"str\") + bkt[grp[2]].astype(\"int\").astype(\"str\")\n",
    "    bkt = bkt.pivot(columns=grp[1]+grp[2], values=\"Wt\"+col).reset_index(\"date\")\n",
    "    bkt.to_csv(\"C:/Data/Thesis/Size_BMm_Prior_S_{}.csv\".format(col))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM and Inv are annually rebalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2370047, 49)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = df[df.ME_JunBkt==1]\n",
    "\n",
    "sdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $BM$ Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk = sdf[(sdf.EXCHCD==1) & (sdf.date.dt.month==7) & (sdf.BMOK)][[\"HP\", \"BM\"]].groupby(\"HP\")\n",
    "brk = brk.quantile(pcts).unstack()\n",
    "brk.columns = brk.columns.droplevel(0)\n",
    "\n",
    "sdf = sdf.merge(brk.reset_index(\"HP\"), on=\"HP\", how=\"left\")\n",
    "sdf = assign_bkts(sdf, \"BM\", pcts)\n",
    "\n",
    "sdf = sdf.drop(pcts, axis=1)\n",
    "\n",
    "assert sdf.BMBkt.isna().sum() != sdf.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inv Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk = sdf[(sdf.EXCHCD==1) & (sdf.date.dt.month==7) & (~sdf.Inv.isna())][[\"HP\", \"Inv\"]].groupby(\"HP\")\n",
    "brk = brk.quantile(pcts).unstack()\n",
    "brk.columns = brk.columns.droplevel(0)\n",
    "\n",
    "sdf = sdf.merge(brk.reset_index(\"HP\"), on=\"HP\", how=\"left\")\n",
    "sdf = assign_bkts(sdf, \"Inv\", pcts)\n",
    "\n",
    "sdf = sdf.drop(pcts, axis=1)\n",
    "\n",
    "assert sdf.InvBkt.isna().sum() != sdf.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size-Value-Investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RET BMm BM Prior CP Var_ret L1_Var_ret Inv F1_Inv BE_Growth_Future \n"
     ]
    }
   ],
   "source": [
    "grp, ix = [\"date\", \"BMBkt\", \"InvBkt\"], ((~sdf.Size.isna()) & (sdf.BMOK) & (~sdf.Inv.isna()))\n",
    "\n",
    "sdf[\"BktSize\"] = sdf[ix].groupby(grp)[\"Size\"].transform(\"sum\")\n",
    "\n",
    "for col in cols:\n",
    "    print(col, end=\" \")\n",
    "    sdf[\"Wt\"+col] = sdf[col] * sdf.Size / sdf.BktSize\n",
    "    bkt = sdf[ix].groupby(grp)[\"Wt\"+col].sum()\n",
    "    bkt = bkt.reset_index(grp[1:])\n",
    "    bkt[grp[1]+grp[2]] = \"S\" + bkt[grp[1]].astype(\"int\").astype(\"str\") + bkt[grp[2]].astype(\"int\").astype(\"str\")\n",
    "    bkt = bkt.pivot(columns=grp[1]+grp[2], values=\"Wt\"+col).reset_index(\"date\")\n",
    "    bkt.to_csv(\"C:/Data/Thesis/Size_BM_Inv_S_{}.csv\".format(col))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(597052, 49)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = df[df.L1_MEBkt==2]\n",
    "\n",
    "sdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $BM^m$ Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk = sdf[[\"date\", \"BMm\"]][(sdf.EXCHCD==1) & (sdf.BMmOK)].groupby(\"date\")\n",
    "brk = brk.quantile(pcts).unstack()\n",
    "brk.columns = brk.columns.droplevel(0)\n",
    "\n",
    "brk = brk.reset_index(\"date\")\n",
    "brk.date = pd.to_datetime(brk.date)\n",
    "\n",
    "sdf = sdf.merge(brk, on=\"date\", how=\"left\")\n",
    "sdf = assign_bkts(sdf, \"BMm\", pcts)\n",
    "\n",
    "sdf = sdf.drop(pcts, axis=1)\n",
    "\n",
    "assert sdf.BMmBkt.isna().sum() != sdf.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk = sdf[[\"date\", \"Prior\"]][(sdf.EXCHCD==1) & (sdf.PriorOK)].groupby(\"date\")\n",
    "brk = brk.quantile(pcts).unstack()\n",
    "brk.columns = brk.columns.droplevel(0)\n",
    "\n",
    "brk = brk.reset_index(\"date\")\n",
    "brk.date = pd.to_datetime(brk.date)\n",
    "\n",
    "sdf = sdf.merge(brk, on=\"date\", how=\"left\")\n",
    "sdf = assign_bkts(sdf, \"Prior\", pcts)\n",
    "\n",
    "sdf = sdf.drop(pcts, axis=1)\n",
    "\n",
    "assert sdf.PriorBkt.isna().sum() != sdf.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size-Value-Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RET BMm BM Prior CP Var_ret L1_Var_ret Inv F1_Inv BE_Growth_Future \n"
     ]
    }
   ],
   "source": [
    "grp, ix = [\"date\", \"BMmBkt\", \"PriorBkt\"], ((~sdf.L1_MEBkt.isna()) & (sdf.BMmOK) & (sdf.PriorOK))\n",
    "\n",
    "sdf[\"BktSize\"] = sdf[ix].groupby(grp)[\"L1_ME\"].transform(\"sum\")\n",
    "\n",
    "for col in cols:\n",
    "    print(col, end=\" \")\n",
    "    sdf[\"Wt\"+col] = sdf[col] * sdf.L1_ME / sdf.BktSize\n",
    "    bkt = sdf[ix].groupby(grp)[\"Wt\"+col].sum()\n",
    "    bkt = bkt.reset_index(grp[1:])\n",
    "    bkt[grp[1]+grp[2]] = \"B\" + bkt[grp[1]].astype(\"int\").astype(\"str\") + bkt[grp[2]].astype(\"int\").astype(\"str\")\n",
    "    bkt = bkt.pivot(columns=grp[1]+grp[2], values=\"Wt\"+col).reset_index(\"date\")\n",
    "    bkt.to_csv(\"C:/Data/Thesis/Size_BMm_Prior_B_{}.csv\".format(col))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM and Inv are annually rebalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581661, 49)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = df[df.ME_JunBkt==2]\n",
    "\n",
    "sdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $BM$ Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk = sdf[(sdf.EXCHCD==1) & (sdf.date.dt.month==7) & (sdf.BMOK)][[\"HP\", \"BM\"]].groupby(\"HP\")\n",
    "brk = brk.quantile(pcts).unstack()\n",
    "brk.columns = brk.columns.droplevel(0)\n",
    "\n",
    "sdf = sdf.merge(brk.reset_index(\"HP\"), on=\"HP\", how=\"left\")\n",
    "sdf = assign_bkts(sdf, \"BM\", pcts)\n",
    "\n",
    "sdf = sdf.drop(pcts, axis=1)\n",
    "\n",
    "assert sdf.BMBkt.isna().sum() != sdf.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inv Buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "brk = sdf[(sdf.EXCHCD==1) & (sdf.date.dt.month==7) & (~sdf.Inv.isna())][[\"HP\", \"Inv\"]].groupby(\"HP\")\n",
    "brk = brk.quantile(pcts).unstack()\n",
    "brk.columns = brk.columns.droplevel(0)\n",
    "\n",
    "sdf = sdf.merge(brk.reset_index(\"HP\"), on=\"HP\", how=\"left\")\n",
    "sdf = assign_bkts(sdf, \"Inv\", pcts)\n",
    "\n",
    "sdf = sdf.drop(pcts, axis=1)\n",
    "\n",
    "assert sdf.InvBkt.isna().sum() != sdf.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size-Value-Investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RET BMm BM Prior CP Var_ret L1_Var_ret Inv F1_Inv BE_Growth_Future \n"
     ]
    }
   ],
   "source": [
    "grp, ix = [\"date\", \"BMBkt\", \"InvBkt\"], ((~sdf.Size.isna()) & (sdf.BMOK) & (~sdf.Inv.isna()))\n",
    "\n",
    "sdf[\"BktSize\"] = sdf[ix].groupby(grp)[\"Size\"].transform(\"sum\")\n",
    "\n",
    "for col in cols:\n",
    "    print(col, end=\" \")\n",
    "    sdf[\"Wt\"+col] = sdf[col] * sdf.Size / sdf.BktSize\n",
    "    bkt = sdf[ix].groupby(grp)[\"Wt\"+col].sum()\n",
    "    bkt = bkt.reset_index(grp[1:])\n",
    "    bkt[grp[1]+grp[2]] = \"B\" + bkt[grp[1]].astype(\"int\").astype(\"str\") + bkt[grp[2]].astype(\"int\").astype(\"str\")\n",
    "    bkt = bkt.pivot(columns=grp[1]+grp[2], values=\"Wt\"+col).reset_index(\"date\")\n",
    "    bkt.to_csv(\"C:/Data/Thesis/Size_BM_Inv_B_{}.csv\".format(col))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Small and Big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RET', 'BMm', 'BM', 'Prior', 'CP', 'Var_ret', 'L1_Var_ret', 'Inv', 'F1_Inv', 'BE_Growth_Future']\n"
     ]
    }
   ],
   "source": [
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"Size_BMm_Prior\"\n",
    "\n",
    "BMm_Prior = OrderedDict()\n",
    "\n",
    "for col, display in zip(\n",
    "    cols,\n",
    "    [r\"$\\text{R}^i$\", r\"$\\text{BM}^m$\", \"BM\", \"Prior\", \"CP\", \"Var\", \"Future Var\",\n",
    "     \"Inv\", \"Future Inv\", r\"Future $\\Delta\\text{BE}$\"]):\n",
    "    # BM_Inv[col] = {\"small\": None, \"big\": None}\n",
    "    BMm_Prior[col] = {\"coef\": None, \"display\": display}\n",
    "    multiplier = 100 if col in [\"RET\", \"Var_ret\", \"L1_Var_ret\"] else 1\n",
    "\n",
    "    small = pd.read_csv(\"C:/Data/Thesis/{}_S_{}.csv\".format(prefix, col)).iloc[:, 1:]\n",
    "    small.date = pd.to_datetime(small.date)\n",
    "    # small = small.set_index(\"date\")[\"1963-07\":\"2017-12\"].replace([pd.np.inf, -pd.np.inf], pd.np.nan).mean() * multiplier\n",
    "    # BM_Inv[col][\"small\"] = small.round(2).values.reshape([4, 4])\n",
    "\n",
    "    big = pd.read_csv(\"C:/Data/Thesis/{}_B_{}.csv\".format(prefix, col)).iloc[:, 1:]\n",
    "    big.date = pd.to_datetime(big.date)\n",
    "    # big = big.set_index(\"date\")[\"1963-07\":\"2017-12\"].replace([pd.np.inf, -pd.np.inf], pd.np.nan).mean() * multiplier\n",
    "    # BM_Inv[col][\"big\"] = small.round(2).values.reshape([4, 4]).transpose()\n",
    "\n",
    "    x = small.merge(big, how=\"left\").set_index(\"date\")[\"1963-07\":\"2017-12\"]\n",
    "    x = x.replace([pd.np.inf, -pd.np.inf], pd.np.nan).mean() * multiplier\n",
    "    BMm_Prior[col][\"coef\"] = x.round(2).values.reshape([2, 4, 4]).transpose((0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size_BMm_Prior_chars_tbl.tex\n"
     ]
    }
   ],
   "source": [
    "label = \"{}_chars\".format(prefix)\n",
    "fname = \"{}_tbl.tex\".format(label)\n",
    "\n",
    "context = {\"coefs\": BMm_Prior, \"K\": 2, \"I\":4, \"J\": 4,\n",
    "           \"caption\": \"Barnacles\", \"label\": \"tbl:\"+label, \"font_size\": r\"\\scriptsize\",\n",
    "           \"K_hdrs\": [\"Small\", \"Big\"], \"col_name\": r\"$\\text{BM}^m$\",\n",
    "           \"col_names\": [\"Low\", \"2\", \"3\", \"High\"],\n",
    "           \"row_names\": [\"Low Prior\", \"2\", \"3\", \"High Prior\"]}\n",
    "\n",
    "with open(os.path.join(path, fname), \"w\") as table:\n",
    "    table.write(template.render(context))\n",
    "print(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"Size_BM_Inv\"\n",
    "\n",
    "BM_Inv = OrderedDict()\n",
    "\n",
    "for col, display in zip(\n",
    "    cols,\n",
    "    [r\"$\\text{R}^i$\", r\"$\\text{BM}^m$\", \"BM\", \"Prior\", \"CP\", \"Var\", \"Future Var\",\n",
    "     \"Inv\", \"Future Inv\", r\"Future $\\Delta\\text{BE}$\"]):\n",
    "    # BM_Inv[col] = {\"small\": None, \"big\": None}\n",
    "    BM_Inv[col] = {\"coef\": None, \"display\": display}\n",
    "    multiplier = 100 if col in [\"RET\", \"Var_ret\", \"L1_Var_ret\"] else 1\n",
    "\n",
    "    small = pd.read_csv(\"C:/Data/Thesis/{}_S_{}.csv\".format(prefix, col)).iloc[:, 1:]\n",
    "    small.date = pd.to_datetime(small.date)\n",
    "    # small = small.set_index(\"date\")[\"1963-07\":\"2017-12\"].replace([pd.np.inf, -pd.np.inf], pd.np.nan).mean() * multiplier\n",
    "    # BM_Inv[col][\"small\"] = small.round(2).values.reshape([4, 4])\n",
    "\n",
    "    big = pd.read_csv(\"C:/Data/Thesis/{}_B_{}.csv\".format(prefix, col)).iloc[:, 1:]\n",
    "    big.date = pd.to_datetime(big.date)\n",
    "    # big = big.set_index(\"date\")[\"1963-07\":\"2017-12\"].replace([pd.np.inf, -pd.np.inf], pd.np.nan).mean() * multiplier\n",
    "    # BM_Inv[col][\"big\"] = small.round(2).values.reshape([4, 4]).transpose()\n",
    "\n",
    "    x = small.merge(big, how=\"left\").set_index(\"date\")[\"1963-07\":\"2017-12\"]\n",
    "    x = x.replace([pd.np.inf, -pd.np.inf], pd.np.nan).mean() * multiplier\n",
    "    BM_Inv[col][\"coef\"] = x.round(2).values.reshape([2, 4, 4]).transpose((0, 2, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size_BM_Inv_chars_tbl.tex\n"
     ]
    }
   ],
   "source": [
    "label = \"{}_chars\".format(prefix)\n",
    "fname = \"{}_tbl.tex\".format(label)\n",
    "\n",
    "context = {\"coefs\": BM_Inv, \"K\": 2, \"I\":4, \"J\": 4,\n",
    "           \"caption\": \"Barnacles\", \"label\": \"tbl:\"+label, \"font_size\": r\"\\scriptsize\",\n",
    "           \"K_hdrs\": [\"Small\", \"Big\"], \"col_name\": r\"BM\",\n",
    "           \"col_names\": [\"Low\", \"2\", \"3\", \"High\"],\n",
    "           \"row_names\": [\"Low Inv\", \"2\", \"3\", \"High Inv\"]}\n",
    "\n",
    "with open(os.path.join(path, fname), \"w\") as table:\n",
    "    table.write(template.render(context))\n",
    "print(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
